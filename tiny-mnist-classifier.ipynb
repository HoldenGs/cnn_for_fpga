{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-03T23:28:41.967399Z",
     "iopub.status.busy": "2025-03-03T23:28:41.967075Z",
     "iopub.status.idle": "2025-03-03T23:28:44.896598Z",
     "shell.execute_reply": "2025-03-03T23:28:44.895341Z",
     "shell.execute_reply.started": "2025-03-03T23:28:41.967374Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/digit-recognizer/sample_submission.csv\n",
      "/kaggle/input/digit-recognizer/train.csv\n",
      "/kaggle/input/digit-recognizer/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils, models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T23:28:44.898376Z",
     "iopub.status.busy": "2025-03-03T23:28:44.897894Z",
     "iopub.status.idle": "2025-03-03T23:28:44.902510Z",
     "shell.execute_reply": "2025-03-03T23:28:44.901485Z",
     "shell.execute_reply.started": "2025-03-03T23:28:44.898345Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu121\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T23:28:45.771137Z",
     "iopub.status.busy": "2025-03-03T23:28:45.770738Z",
     "iopub.status.idle": "2025-03-03T23:28:45.779294Z",
     "shell.execute_reply": "2025-03-03T23:28:45.778071Z",
     "shell.execute_reply.started": "2025-03-03T23:28:45.771103Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class MNIST_data(Dataset):\n",
    "    \"\"\"MNIST dtaa set\"\"\"\n",
    "    \n",
    "    def __init__(self, file_path, \n",
    "                 transform = transforms.Compose([transforms.ToPILImage(), transforms.ToTensor(), \n",
    "                     transforms.Normalize(mean=(0.5,), std=(0.5,))])\n",
    "                ):\n",
    "        \n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        if len(df.columns) == 784:\n",
    "            # test data\n",
    "            self.X = df.values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]\n",
    "            self.y = None\n",
    "        else:\n",
    "            # training data\n",
    "            self.X = df.iloc[:,1:].values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]\n",
    "            self.y = torch.from_numpy(df.iloc[:,0].values)\n",
    "            \n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is not None:\n",
    "            return self.transform(self.X[idx]), self.y[idx]\n",
    "        else:\n",
    "            return self.transform(self.X[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T23:28:48.075910Z",
     "iopub.status.busy": "2025-03-03T23:28:48.075568Z",
     "iopub.status.idle": "2025-03-03T23:28:53.188643Z",
     "shell.execute_reply": "2025-03-03T23:28:53.187626Z",
     "shell.execute_reply.started": "2025-03-03T23:28:48.075885Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataset = MNIST_data('/kaggle/input/digit-recognizer/train.csv', transform= transforms.Compose(\n",
    "                            [transforms.ToPILImage(), transforms.ToTensor(), transforms.Normalize(mean=(0.5,), std=(0.5,))]))\n",
    "test_dataset = MNIST_data('/kaggle/input/digit-recognizer/test.csv')\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                           batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T23:28:55.445021Z",
     "iopub.status.busy": "2025-03-03T23:28:55.444630Z",
     "iopub.status.idle": "2025-03-03T23:28:55.671194Z",
     "shell.execute_reply": "2025-03-03T23:28:55.670133Z",
     "shell.execute_reply.started": "2025-03-03T23:28:55.444964Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size:\n",
      "12906 parameters\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 1, 28, 28])\n",
      "Predicted digit: 9\n",
      "Output probabilities: [0.0859375  0.03125    0.0703125  0.0625     0.109375   0.0390625\n",
      " 0.01953125 0.06640625 0.046875   0.46484375]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1844: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return inner()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "class OptimizedCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OptimizedCNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3),  # Reduced filters and kernel size\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3),  # Reduced filters and kernel size\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32 * 5 * 5, 10),\n",
    "            nn.Softmax()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "model = OptimizedCNN()\n",
    "\n",
    "model.qconfig = torch.quantization.default_qconfig\n",
    "model_prepared = torch.quantization.prepare_qat(model)\n",
    "\n",
    "print(\"model size:\")\n",
    "print(sum(p.numel() for p in model_prepared.parameters() if p.requires_grad), \"parameters\")\n",
    "\n",
    "# Create a test input (28x28 grayscale image)\n",
    "test_input = torch.randn(1, 1, 28, 28)  # Batch size 1, 1 channel, 28x28 pixels\n",
    "\n",
    "# Display the test input\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(test_input[0, 0].numpy(), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Test Input Image')\n",
    "plt.show()\n",
    "\n",
    "# Print input shape\n",
    "print(f\"Input shape: {test_input.shape}\")\n",
    "\n",
    "# Test the model with the input\n",
    "with torch.no_grad():\n",
    "    output = model_prepared(test_input)\n",
    "    predicted_digit = torch.argmax(output).item()\n",
    "    print(f\"Predicted digit: {predicted_digit}\")\n",
    "    print(f\"Output probabilities: {output[0].numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T23:29:00.093825Z",
     "iopub.status.busy": "2025-03-03T23:29:00.093474Z",
     "iopub.status.idle": "2025-03-03T23:29:00.106047Z",
     "shell.execute_reply": "2025-03-03T23:29:00.105069Z",
     "shell.execute_reply.started": "2025-03-03T23:29:00.093785Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OptimizedCNN(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(\n",
       "      1, 16, kernel_size=(3, 3), stride=(1, 1)\n",
       "      (weight_fake_quant): MinMaxObserver(min_val=-0.33276236057281494, max_val=0.32955655455589294)\n",
       "      (activation_post_process): MinMaxObserver(min_val=-2.4491498470306396, max_val=2.510695219039917)\n",
       "    )\n",
       "    (1): BatchNorm2d(\n",
       "      16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "      (activation_post_process): MinMaxObserver(min_val=-3.6879217624664307, max_val=3.7476508617401123)\n",
       "    )\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(\n",
       "      16, 32, kernel_size=(3, 3), stride=(1, 1)\n",
       "      (weight_fake_quant): MinMaxObserver(min_val=-0.083328977227211, max_val=0.08331044018268585)\n",
       "      (activation_post_process): MinMaxObserver(min_val=-2.461416482925415, max_val=2.594917058944702)\n",
       "    )\n",
       "    (1): BatchNorm2d(\n",
       "      32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "      (activation_post_process): MinMaxObserver(min_val=-3.583470344543457, max_val=3.7196600437164307)\n",
       "    )\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(\n",
       "      in_features=800, out_features=10, bias=True\n",
       "      (weight_fake_quant): MinMaxObserver(min_val=-0.035346221178770065, max_val=0.03534959256649017)\n",
       "      (activation_post_process): MinMaxObserver(min_val=-1.4467216730117798, max_val=1.7028218507766724)\n",
       "    )\n",
       "    (2): Softmax(\n",
       "      dim=None\n",
       "      (activation_post_process): FixedQParamsFakeQuantize(\n",
       "        fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), scale=tensor([0.0039]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine\n",
       "        (activation_post_process): FixedQParamsObserver()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T23:29:03.152627Z",
     "iopub.status.busy": "2025-03-03T23:29:03.152288Z",
     "iopub.status.idle": "2025-03-03T23:29:03.157498Z",
     "shell.execute_reply": "2025-03-03T23:29:03.156360Z",
     "shell.execute_reply.started": "2025-03-03T23:29:03.152599Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# if(torch.cuda.is_available()):\n",
    "#     model_prepared = model_prepared.cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model_prepared.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T23:29:05.443923Z",
     "iopub.status.busy": "2025-03-03T23:29:05.443585Z",
     "iopub.status.idle": "2025-03-03T23:36:15.422213Z",
     "shell.execute_reply": "2025-03-03T23:36:15.421150Z",
     "shell.execute_reply.started": "2025-03-03T23:29:05.443898Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training....\n",
      "Epoch: 0 Batch: 100 loss: 2.120450735092163\n",
      "Epoch: 0 Batch: 200 loss: 1.8638532161712646\n",
      "Epoch: 0 Batch: 300 loss: 1.7470965385437012\n",
      "Epoch: 0 Batch: 400 loss: 1.7991697788238525\n",
      "Epoch: 0 Batch: 500 loss: 1.69730544090271\n",
      "Epoch: 0 Batch: 600 loss: 1.7072259187698364\n",
      "Epoch: 1 Batch: 100 loss: 1.6724646091461182\n",
      "Epoch: 1 Batch: 200 loss: 1.6629966497421265\n",
      "Epoch: 1 Batch: 300 loss: 1.6116080284118652\n",
      "Epoch: 1 Batch: 400 loss: 1.6446120738983154\n",
      "Epoch: 1 Batch: 500 loss: 1.6088331937789917\n",
      "Epoch: 1 Batch: 600 loss: 1.5998561382293701\n",
      "Epoch: 2 Batch: 100 loss: 1.6459248065948486\n",
      "Epoch: 2 Batch: 200 loss: 1.6953494548797607\n",
      "Epoch: 2 Batch: 300 loss: 1.5828557014465332\n",
      "Epoch: 2 Batch: 400 loss: 1.5574270486831665\n",
      "Epoch: 2 Batch: 500 loss: 1.6122158765792847\n",
      "Epoch: 2 Batch: 600 loss: 1.6902621984481812\n",
      "Epoch: 3 Batch: 100 loss: 1.5719926357269287\n",
      "Epoch: 3 Batch: 200 loss: 1.6234921216964722\n",
      "Epoch: 3 Batch: 300 loss: 1.6299961805343628\n",
      "Epoch: 3 Batch: 400 loss: 1.5670894384384155\n",
      "Epoch: 3 Batch: 500 loss: 1.709006905555725\n",
      "Epoch: 3 Batch: 600 loss: 1.6652053594589233\n",
      "Epoch: 4 Batch: 100 loss: 1.624651551246643\n",
      "Epoch: 4 Batch: 200 loss: 1.6347942352294922\n",
      "Epoch: 4 Batch: 300 loss: 1.5729597806930542\n",
      "Epoch: 4 Batch: 400 loss: 1.621190071105957\n",
      "Epoch: 4 Batch: 500 loss: 1.5929851531982422\n",
      "Epoch: 4 Batch: 600 loss: 1.5776736736297607\n",
      "Epoch: 5 Batch: 100 loss: 1.6547961235046387\n",
      "Epoch: 5 Batch: 200 loss: 1.544640302658081\n",
      "Epoch: 5 Batch: 300 loss: 1.5580495595932007\n",
      "Epoch: 5 Batch: 400 loss: 1.6059978008270264\n",
      "Epoch: 5 Batch: 500 loss: 1.6090439558029175\n",
      "Epoch: 5 Batch: 600 loss: 1.5925276279449463\n",
      "Epoch: 6 Batch: 100 loss: 1.6239712238311768\n",
      "Epoch: 6 Batch: 200 loss: 1.5521420240402222\n",
      "Epoch: 6 Batch: 300 loss: 1.610314965248108\n",
      "Epoch: 6 Batch: 400 loss: 1.5780149698257446\n",
      "Epoch: 6 Batch: 500 loss: 1.5813642740249634\n",
      "Epoch: 6 Batch: 600 loss: 1.5505403280258179\n",
      "Epoch: 7 Batch: 100 loss: 1.5399422645568848\n",
      "Epoch: 7 Batch: 200 loss: 1.547340750694275\n",
      "Epoch: 7 Batch: 300 loss: 1.5763846635818481\n",
      "Epoch: 7 Batch: 400 loss: 1.5964747667312622\n",
      "Epoch: 7 Batch: 500 loss: 1.5475752353668213\n",
      "Epoch: 7 Batch: 600 loss: 1.539350152015686\n",
      "Epoch: 8 Batch: 100 loss: 1.5048096179962158\n",
      "Epoch: 8 Batch: 200 loss: 1.4998559951782227\n",
      "Epoch: 8 Batch: 300 loss: 1.5081721544265747\n",
      "Epoch: 8 Batch: 400 loss: 1.5024497509002686\n",
      "Epoch: 8 Batch: 500 loss: 1.5042082071304321\n",
      "Epoch: 8 Batch: 600 loss: 1.5142592191696167\n",
      "Epoch: 9 Batch: 100 loss: 1.531704306602478\n",
      "Epoch: 9 Batch: 200 loss: 1.5191010236740112\n",
      "Epoch: 9 Batch: 300 loss: 1.51326322555542\n",
      "Epoch: 9 Batch: 400 loss: 1.4969518184661865\n",
      "Epoch: 9 Batch: 500 loss: 1.5002589225769043\n",
      "Epoch: 9 Batch: 600 loss: 1.5193307399749756\n",
      "Epoch: 10 Batch: 100 loss: 1.5047872066497803\n",
      "Epoch: 10 Batch: 200 loss: 1.5559723377227783\n",
      "Epoch: 10 Batch: 300 loss: 1.4771499633789062\n",
      "Epoch: 10 Batch: 400 loss: 1.4895365238189697\n",
      "Epoch: 10 Batch: 500 loss: 1.5117515325546265\n",
      "Epoch: 10 Batch: 600 loss: 1.4702653884887695\n",
      "Epoch: 11 Batch: 100 loss: 1.486514925956726\n",
      "Epoch: 11 Batch: 200 loss: 1.4761253595352173\n",
      "Epoch: 11 Batch: 300 loss: 1.5036306381225586\n",
      "Epoch: 11 Batch: 400 loss: 1.4992014169692993\n",
      "Epoch: 11 Batch: 500 loss: 1.5213180780410767\n",
      "Epoch: 11 Batch: 600 loss: 1.4781794548034668\n",
      "Epoch: 12 Batch: 100 loss: 1.5057123899459839\n",
      "Epoch: 12 Batch: 200 loss: 1.4966202974319458\n",
      "Epoch: 12 Batch: 300 loss: 1.5233228206634521\n",
      "Epoch: 12 Batch: 400 loss: 1.5057533979415894\n",
      "Epoch: 12 Batch: 500 loss: 1.4694868326187134\n",
      "Epoch: 12 Batch: 600 loss: 1.4700504541397095\n",
      "Epoch: 13 Batch: 100 loss: 1.5090903043746948\n",
      "Epoch: 13 Batch: 200 loss: 1.48253333568573\n",
      "Epoch: 13 Batch: 300 loss: 1.5077028274536133\n",
      "Epoch: 13 Batch: 400 loss: 1.4981210231781006\n",
      "Epoch: 13 Batch: 500 loss: 1.4793643951416016\n",
      "Epoch: 13 Batch: 600 loss: 1.508238434791565\n",
      "Epoch: 14 Batch: 100 loss: 1.4955357313156128\n",
      "Epoch: 14 Batch: 200 loss: 1.5085256099700928\n",
      "Epoch: 14 Batch: 300 loss: 1.4717422723770142\n",
      "Epoch: 14 Batch: 400 loss: 1.4838765859603882\n",
      "Epoch: 14 Batch: 500 loss: 1.5086033344268799\n",
      "Epoch: 14 Batch: 600 loss: 1.4942377805709839\n",
      "Epoch: 15 Batch: 100 loss: 1.4838873147964478\n",
      "Epoch: 15 Batch: 200 loss: 1.4790087938308716\n",
      "Epoch: 15 Batch: 300 loss: 1.4943822622299194\n",
      "Epoch: 15 Batch: 400 loss: 1.4870377779006958\n",
      "Epoch: 15 Batch: 500 loss: 1.4798399209976196\n",
      "Epoch: 15 Batch: 600 loss: 1.470399260520935\n",
      "Epoch: 16 Batch: 100 loss: 1.4911576509475708\n",
      "Epoch: 16 Batch: 200 loss: 1.4678865671157837\n",
      "Epoch: 16 Batch: 300 loss: 1.526856780052185\n",
      "Epoch: 16 Batch: 400 loss: 1.4899053573608398\n",
      "Epoch: 16 Batch: 500 loss: 1.5001497268676758\n",
      "Epoch: 16 Batch: 600 loss: 1.5244060754776\n",
      "Epoch: 17 Batch: 100 loss: 1.5042001008987427\n",
      "Epoch: 17 Batch: 200 loss: 1.485700249671936\n",
      "Epoch: 17 Batch: 300 loss: 1.51985502243042\n",
      "Epoch: 17 Batch: 400 loss: 1.493901252746582\n",
      "Epoch: 17 Batch: 500 loss: 1.464779019355774\n",
      "Epoch: 17 Batch: 600 loss: 1.5135526657104492\n",
      "Epoch: 18 Batch: 100 loss: 1.5226224660873413\n",
      "Epoch: 18 Batch: 200 loss: 1.4848037958145142\n",
      "Epoch: 18 Batch: 300 loss: 1.4910997152328491\n",
      "Epoch: 18 Batch: 400 loss: 1.490258812904358\n",
      "Epoch: 18 Batch: 500 loss: 1.4685440063476562\n",
      "Epoch: 18 Batch: 600 loss: 1.5001180171966553\n",
      "Epoch: 19 Batch: 100 loss: 1.4867929220199585\n",
      "Epoch: 19 Batch: 200 loss: 1.4701508283615112\n",
      "Epoch: 19 Batch: 300 loss: 1.4829853773117065\n",
      "Epoch: 19 Batch: 400 loss: 1.4746052026748657\n",
      "Epoch: 19 Batch: 500 loss: 1.4908307790756226\n",
      "Epoch: 19 Batch: 600 loss: 1.4658434391021729\n",
      "Training Completed in: 429.97130823135376 secs\n",
      "Training accuracy: 92.87476190476191 %\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "print('Training....')\n",
    "total = 0\n",
    "correct = 0\n",
    "start = time.time()\n",
    "\n",
    "for epoch in range(40):\n",
    "    \n",
    "    for i, data in enumerate(train_loader, 1):\n",
    "        images, labels = data\n",
    "\n",
    "        #if(torch.cuda.is_available()):\n",
    "        # images = images.cuda()\n",
    "        # labels = labels.cuda()\n",
    "\n",
    "        optimizer.zero_grad()    \n",
    "        outputs = model_prepared(images)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        if(i%100 == 0):\n",
    "            print('Epoch: {} Batch: {} loss: {}'.format(epoch, i, loss.item()))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "model_int8 = torch.quantization.convert(model_prepared)\n",
    "\n",
    "print('Training Completed in: {} secs'.format(time.time()-start))\n",
    "print('Training accuracy: {} %'.format((correct/total)*100))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T23:37:44.945306Z",
     "iopub.status.busy": "2025-03-03T23:37:44.944921Z",
     "iopub.status.idle": "2025-03-03T23:37:54.504910Z",
     "shell.execute_reply": "2025-03-03T23:37:54.503832Z",
     "shell.execute_reply.started": "2025-03-03T23:37:44.945274Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 100 done\n",
      "Batch 200 done\n",
      "Batch 300 done\n",
      "Batch 400 done\n",
      "Completed in 9.553915023803711 secs\n"
     ]
    }
   ],
   "source": [
    "print('Predicting....')\n",
    "start = time.time()\n",
    "\n",
    "predictions = torch.LongTensor()\n",
    "for i, data in enumerate(test_loader, 1):\n",
    "    data = data\n",
    "    \n",
    "    if(i%100 == 0):\n",
    "        print('Batch {} done'.format(i))\n",
    "    outputs = model(data)\n",
    "    \n",
    "    pred = outputs.data.max(1, keepdim=True)[1]\n",
    "    predictions = torch.cat((predictions, pred), dim=0)\n",
    "    \n",
    "print('Completed in {} secs'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T23:38:13.343194Z",
     "iopub.status.busy": "2025-03-03T23:38:13.342835Z",
     "iopub.status.idle": "2025-03-03T23:38:13.354565Z",
     "shell.execute_reply": "2025-03-03T23:38:13.353474Z",
     "shell.execute_reply.started": "2025-03-03T23:38:13.343168Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Quantize model\n",
    "\n",
    "model_int8 = torch.quantization.convert(model, inplace=False)\n",
    "\n",
    "# Save the quantized model\n",
    "torch.save(model_int8, '/kaggle/working/model_dynamic_quantized.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-03-03T23:26:12.936Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_file_size_kb(file_path):\n",
    "  \"\"\"\n",
    "    Retrieves the size of a file in kilobytes.\n",
    "\n",
    "    Args:\n",
    "        file_path: The path to the file.\n",
    "\n",
    "    Returns:\n",
    "        The file size in kilobytes, or None if the file does not exist.\n",
    "    \"\"\"\n",
    "  try:\n",
    "    size_bytes = os.path.getsize(file_path)\n",
    "    size_kb = size_bytes / 1024\n",
    "    return size_kb\n",
    "  except FileNotFoundError:\n",
    "    return None\n",
    "\n",
    "# Example usage:\n",
    "file_path = \"model_dynamic_quantized.pth\"  # Replace with your file path\n",
    "file_size_kb = get_file_size_kb(file_path)\n",
    "\n",
    "if file_size_kb is not None:\n",
    "  print(f\"The size of '{file_path}' is: {file_size_kb:.2f} KB\")\n",
    "else:\n",
    "  print(f\"File '{file_path}' not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-03-03T23:26:12.936Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets\n",
    "\n",
    "# Load MNIST dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "mnist_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "\n",
    "# Sample a random image from MNIST\n",
    "sample_idx = torch.randint(0, len(mnist_dataset), (1,)).item()\n",
    "sample_image, sample_label = mnist_dataset[sample_idx]\n",
    "\n",
    "# Display the image\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(sample_image[0].numpy(), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title(f'True Label: {sample_label}')\n",
    "plt.show()\n",
    "\n",
    "# Prepare the image for the model (add batch dimension)\n",
    "model_input = sample_image.unsqueeze(0)\n",
    "\n",
    "# Get model prediction\n",
    "with torch.no_grad():\n",
    "    output = model_optimized(model_input)\n",
    "    predicted_digit = torch.argmax(output).item()\n",
    "    probabilities = output[0].numpy()\n",
    "    \n",
    "    print(f\"True Label: {sample_label}\")\n",
    "    print(f\"Predicted Label: {predicted_digit}\")\n",
    "    print(\"\\nProbabilities for each digit:\")\n",
    "    for i, prob in enumerate(probabilities):\n",
    "        print(f\"Digit {i}: {prob:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-03-03T23:26:12.936Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "out_df = pd.DataFrame(np.c_[np.arange(1, len(test_dataset)+1)[:,None], predictions.numpy()], columns=['ImageId', 'Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-03-03T23:26:12.936Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "out_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-03-03T23:26:12.936Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "out_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 861823,
     "sourceId": 3004,
     "sourceType": "competition"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
